{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOd5Gcl2ZKU4gyTiHjwIubb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naomie25/DI-Bootcamp/blob/main/Week10_Day2_ExerciceXP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1 : Gradio Interface - Multi-Function Toolkit\n"
      ],
      "metadata": {
        "id": "8Zh18GHRWVZS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ex_6IR8sWSam"
      },
      "outputs": [],
      "source": [
        "!pip install gradio streamlit fastapi -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def square_fct(number):\n",
        "  return number**2\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "  name_state=gr.State()\n",
        "  with gr.Tab(\"Greet\"):\n",
        "    name_input=gr.Textbox(label=\"Name\")\n",
        "    greet_button=gr.Button(\"Greet\")\n",
        "    greet_output=gr.Textbox(label=\"Greeting\")\n",
        "    greet_button.click(fn=lambda name: f\"Hello {name}!\", inputs=name_input, outputs=greet_output)\n",
        "\n",
        "  with gr.Tab(\"Echo\"):\n",
        "    echo_input=gr.Textbox(label=\"Text\")\n",
        "    echo_button=gr.Button(\"Echo\")\n",
        "    echo_output=gr.Textbox(label=\"Echo Output\")\n",
        "    echo_button.click(fn=lambda text: f\"You said: {text}\", inputs=echo_input, outputs=echo_output)\n",
        "\n",
        "  with gr.Tab(\"Square a number\"):\n",
        "    square_input=gr.Number(label=\"Number\")\n",
        "    square_button=gr.Button(\"Square\")\n",
        "    square_output=gr.Number(label=\"Square Output\")\n",
        "    square_button.click(fn=square_fct, inputs=square_input, outputs=square_output)\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "5PSgQmPEXgQt",
        "outputId": "c6bd9d67-0020-45f3-d4ba-e4f0d5a47244"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://542fdc558c03419688.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://542fdc558c03419688.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 2 : Gradio Blocks - Simple Two-Step Calculator"
      ],
      "metadata": {
        "id": "2ApTPDZGbqrk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "2d9ce261",
        "outputId": "a5b783b9-637d-4933-c686-377820363860"
      },
      "source": [
        "import gradio as gr\n",
        "\n",
        "def calculate(num1, num2, operation):\n",
        "    if operation == \"Add\":\n",
        "        return num1 + num2\n",
        "    elif operation == \"Multiply\":\n",
        "        return num1 * num2\n",
        "    else:\n",
        "        return \"Invalid operation\"\n",
        "\n",
        "with gr.Blocks() as calculator_demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # Simple Two-Step Calculator\n",
        "    Enter two numbers and select an operation to perform the calculation.\n",
        "    \"\"\")\n",
        "    with gr.Row():\n",
        "        num1_input = gr.Number(label=\"First Number\")\n",
        "        num2_input = gr.Number(label=\"Second Number\")\n",
        "\n",
        "    operation_radio = gr.Radio([\"Add\", \"Multiply\"], label=\"Operation\")\n",
        "    calculate_button = gr.Button(\"Calculate\")\n",
        "    result_output = gr.Label(label=\"Result\")\n",
        "\n",
        "    calculate_button.click(\n",
        "        fn=calculate,\n",
        "        inputs=[num1_input, num2_input, operation_radio],\n",
        "        outputs=result_output\n",
        "    )\n",
        "\n",
        "calculator_demo.launch()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://c8b6f8079c313b7a9c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c8b6f8079c313b7a9c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 3 : Streamlit Chat - Stateful Memory Bot"
      ],
      "metadata": {
        "id": "x7Y_YwqDdtRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit pyngrok"
      ],
      "metadata": {
        "id": "sk8HUcn3dt2e"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0810be52",
        "outputId": "60a9a3bb-fd71-4177-841c-3abaa9eaa2f2"
      },
      "source": [
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write('''\n",
        "import streamlit as st\n",
        "\n",
        "# 🎯 Titre de l'application\n",
        "st.set_page_config(page_title=\"🗨️ Chatbot Memory Demo\")\n",
        "\n",
        "st.title(\"🧠 Chatbot with Memory\")\n",
        "\n",
        "# ✅ Initialiser l'historique de conversation\n",
        "if \"chat_history\" not in st.session_state:\n",
        "    st.session_state.chat_history = []\n",
        "\n",
        "# ✅ Afficher les messages précédents\n",
        "for message in st.session_state.chat_history:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "\n",
        "# ✅ Zone de saisie utilisateur\n",
        "user_input = st.chat_input(\"Type your message...\")\n",
        "\n",
        "# ✅ Si un message est soumis\n",
        "if user_input:\n",
        "    # Ajouter le message utilisateur\n",
        "    st.session_state.chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.markdown(user_input)\n",
        "\n",
        "    # Réponse du bot (écho pour l'instant)\n",
        "    bot_response = f\"Echo: {user_input}\"\n",
        "    st.session_state.chat_history.append({\"role\": \"assistant\", \"content\": bot_response})\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        st.markdown(bot_response)\n",
        "\n",
        "# ✅ Bouton pour effacer l'historique\n",
        "if st.button(\"Clear Chat\"):\n",
        "    st.session_state[\"chat_history\"] = []\n",
        "    st.rerun()\n",
        "\n",
        "''')\n",
        "\n",
        "# ✅ 3. Lancer Streamlit avec ngrok\n",
        "from pyngrok import ngrok\n",
        "!streamlit run app.py &> /dev/null &\n",
        "# Token\n",
        "ngrok.set_auth_token(\"30Jn6l3th1QZJmfJTvckXck98GN_2kigNX3N7xixrapYoXsdW\")\n",
        "public_url = ngrok.connect(\"http://localhost:8501\")\n",
        "print(\"🔗 Open your chatbot here:\", public_url)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔗 Open your chatbot here: NgrokTunnel: \"https://4dec518e73d5.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 4 : Streamlit UI + Logic Combo"
      ],
      "metadata": {
        "id": "8r8gxH_yfYJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit colabcode --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz6f-U2jg--9",
        "outputId": "b96603e7-a301-4425-eef2-c056a7f33f62"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring version 0.13.1 of uvicorn since it has invalid metadata:\n",
            "Requested uvicorn==0.13.1 from https://files.pythonhosted.org/packages/ef/67/546c35e9fffb585ea0608ba3bdcafe17ae402e304367203d0b08d6c23051/uvicorn-0.13.1-py3-none-any.whl (from colabcode) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    python-dotenv (>=0.13.*) ; extra == 'standard'\n",
            "                   ~~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring version 0.13.1 of uvicorn since it has invalid metadata:\n",
            "Requested uvicorn==0.13.1 from https://files.pythonhosted.org/packages/ef/67/546c35e9fffb585ea0608ba3bdcafe17ae402e304367203d0b08d6c23051/uvicorn-0.13.1-py3-none-any.whl (from colabcode) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    python-dotenv (>=0.13.*) ; extra == 'standard'\n",
            "                   ~~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring version 0.13.1 of uvicorn since it has invalid metadata:\n",
            "Requested uvicorn==0.13.1 from https://files.pythonhosted.org/packages/ef/67/546c35e9fffb585ea0608ba3bdcafe17ae402e304367203d0b08d6c23051/uvicorn-0.13.1-py3-none-any.whl (from colabcode) has invalid metadata: .* suffix can only be used with `==` or `!=` operators\n",
            "    python-dotenv (>=0.13.*) ; extra == 'standard'\n",
            "                   ~~~~~~~^\n",
            "Please use pip<24.1 if you need to use this version.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "\n",
        "st.title(\"📊 Mini Dashboard interactif\")\n",
        "\n",
        "data = np.random.randn(20, 3)\n",
        "st.line_chart(data)\n",
        "\n",
        "choice = st.radio(\"Que souhaitez-vous afficher ?\", [\"Show Code\", \"Show JSON\"])\n",
        "\n",
        "if choice == \"Show Code\":\n",
        "    code_snippet = '''\n",
        "def greet(name):\n",
        "    return f\"Hello, {name}!\"\n",
        "'''\n",
        "    st.code(code_snippet, language=\"python\")\n",
        "\n",
        "elif choice == \"Show JSON\":\n",
        "    sample_json = {\n",
        "        \"app\": \"Mini Dashboard\",\n",
        "        \"version\": \"1.0\",\n",
        "        \"features\": [\"graph\", \"code display\", \"json display\", \"image loading\"]\n",
        "    }\n",
        "    st.json(sample_json)\n",
        "\n",
        "image_url = \"https://streamlit.io/images/brand/streamlit-logo-secondary-colormark-darktext.png\"\n",
        "st.image(image_url, caption=\"Logo Streamlit\", use_container_width=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiBTKFmShAGt",
        "outputId": "5119b4ef-87a4-463e-d1f4-e78d841ae488"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Fermer tous les tunnels existants\n",
        "ngrok.kill()\n",
        "\n",
        "# Ouvrir tunnel sur le port 8501 (uniquement le numéro de port)\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Streamlit accessible sur :\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_8l0h_MhEkx",
        "outputId": "0eeb6038-6adf-4048-f5bd-a377ea703bcd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit accessible sur : NgrokTunnel: \"https://2b24e610bdf2.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 5 : FastAPI - Smart Responder"
      ],
      "metadata": {
        "id": "oJ23T3xoh8VC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn nest-asyncio pyngrok --quiet"
      ],
      "metadata": {
        "id": "0C8tjS28iIhy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Write FastAPI app to main.py\n",
        "%%writefile main.py\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "class RequestBody(BaseModel):\n",
        "    message: str\n",
        "\n",
        "@app.post(\"/respond\")\n",
        "async def respond(body: RequestBody):\n",
        "    msg = body.message.lower()\n",
        "    if \"math\" in msg:\n",
        "        return {\"response\": \"Using calculator tool...\"}\n",
        "    elif \"date\" in msg:\n",
        "        return {\"response\": \"Fetching current date...\"}\n",
        "    else:\n",
        "        return {\"response\": \"Default LLM response.\"}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBhYErMbh8oJ",
        "outputId": "181200c5-ec5d-4ae0-8484-ee641db98458"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Run FastAPI app with ngrok tunnel\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "import threading\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Open ngrok tunnel on port 8000\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"🚀 Public URL: {public_url}\")\n",
        "\n",
        "# Run uvicorn server in a separate thread\n",
        "config = uvicorn.Config(\"main:app\", host=\"0.0.0.0\", port=8000, log_level=\"info\")\n",
        "server = uvicorn.Server(config)\n",
        "\n",
        "thread = threading.Thread(target=server.run)\n",
        "thread.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po5AJpw6iR3R",
        "outputId": "f65bc734-d50f-4e85-8eef-7c6db6cadec5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Public URL: NgrokTunnel: \"https://b62422ff82c3.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [1168]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Test the endpoint using requests\n",
        "import requests\n",
        "import time\n",
        "\n",
        "# Wait a moment to ensure the server is running\n",
        "time.sleep(5)\n",
        "\n",
        "test_url = public_url.public_url + \"/respond\"\n",
        "\n",
        "\n",
        "# Example test messages\n",
        "test_messages = [\n",
        "    {\"message\": \"Can you do some math?\"},\n",
        "    {\"message\": \"What's the date today?\"},\n",
        "    {\"message\": \"Hello, how are you?\"}\n",
        "]\n",
        "\n",
        "for msg in test_messages:\n",
        "    response = requests.post(test_url, json=msg)\n",
        "    print(f\"Input: {msg['message']}\")\n",
        "    print(\"Response:\", response.json())\n",
        "    print(\"-\" * 30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBXtAoY_iZAR",
        "outputId": "b1841953-93f8-4f98-b67c-2599fdc574fb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:     35.221.153.61:0 - \"POST /respond HTTP/1.1\" 200 OK\n",
            "Input: Can you do some math?\n",
            "Response: {'response': 'Using calculator tool...'}\n",
            "------------------------------\n",
            "INFO:     35.221.153.61:0 - \"POST /respond HTTP/1.1\" 200 OK\n",
            "Input: What's the date today?\n",
            "Response: {'response': 'Fetching current date...'}\n",
            "------------------------------\n",
            "INFO:     35.221.153.61:0 - \"POST /respond HTTP/1.1\" 200 OK\n",
            "Input: Hello, how are you?\n",
            "Response: {'response': 'Default LLM response.'}\n",
            "------------------------------\n"
          ]
        }
      ]
    }
  ]
}