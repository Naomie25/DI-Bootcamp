{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNYNskvGaoKymOdCnNZoUGm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naomie25/DI-Bootcamp/blob/main/Week9_Day2_ExerciceXP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1: Setup and Environment Configuration"
      ],
      "metadata": {
        "id": "H5_En3GuhMtc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7z02hJzbuoJ",
        "outputId": "f102c52b-5743-4bec-cb55-28f6c2077744"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "print(langchain.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GjXrKQ8hQ20",
        "outputId": "3a141772-7394-4771-f8c5-0c2bd46f0d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LANGSMITH_API_KEY=\"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\"\n",
        "import getpass\n",
        "import os\n",
        "\n",
        "# Enable LangSmith tracing\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
        "# Securely input your LangSmith API key\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(prompt=\"LangSmith API Key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0WRSLjriG3W",
        "outputId": "5c05ba93-aee1-4c83-8812-bf064f8b96ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangSmith API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "TAVILY_API_KEY  = \"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\"\n",
        "# Securely input your Tavily API key\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(prompt=\"Tavily API Key: \")"
      ],
      "metadata": {
        "id": "Fc9-mNYbiYG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c9a0e11-6a09-4453-b63a-449336ef54fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tavily API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "assert os.getenv(\"LANGSMITH_TRACING\") == \"true\"\n",
        "assert os.getenv(\"LANGSMITH_API_KEY\") is not None\n",
        "assert os.getenv(\"TAVILY_API_KEY\") is not None\n",
        "print(\"Environment configured successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4WczdvOjIM7",
        "outputId": "7b5a57c8-1c53-469b-fa1d-aba4f7b40174"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment configured successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Exercise 2: Define Tools"
      ],
      "metadata": {
        "id": "TK2LmwK5jRPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26K8AWIAivaP",
        "outputId": "74880af3-6781-4bde-d0ef-c77fb75ceaa2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.72)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-community-0.3.27 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults"
      ],
      "metadata": {
        "id": "tJz5SjXojcpI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search = TavilySearchResults()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAsnnnu2jfcc",
        "outputId": "f0aad5e0-9bf4-4aa5-de32-11484f50e026"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-8-1244456812.py:1: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  search = TavilySearchResults()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_results = search.run(\"latest advancements in AI-driven healthcare triage\")\n",
        "print(search_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yftZhjJYjh06",
        "outputId": "52926b47-4e4d-4ff7-cb8b-c556da374425"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'title': 'Why Artificial Intelligence In Healthcare Is Rewriting Medical ...', 'url': 'https://globalrph.com/2025/02/why-artificial-intelligence-in-healthcare-is-rewriting-medical-diagnosis-in-2025/', 'content': 'Looking ahead, market projections indicate explosive growth, with the AI diagnostics sector expected to reach $10.15 billion by 2033. Emerging technologies promise enhanced capabilities through multimodal analysis, automated reporting, and sophisticated pattern recognition. These advancements signal a fundamental shift toward preventative, data-driven healthcare models that prioritize early intervention and personalized treatment strategies. [...] Remote Diagnostic Capabilities:  \\n AI-driven telemedicine has become the life-blood of remote healthcare delivery. This technology lets patients access services from home while healthcare professionals track vital signs and step in quickly when needed. People in remote areas can now use AI-powered platforms to: Consult with physicians. Get accurate diagnoses. Get treatment plans. Access specialized care they couldn‚Äôt before in their region. [...] Artificial intelligence stands as a cornerstone of modern medical diagnosis, reshaping healthcare delivery through enhanced precision and accessibility. Medical facilities worldwide report substantial improvements, with AI systems achieving diagnostic accuracy rates surpassing 90% across multiple specialties. These technological advances generate annual savings between $200 to 360 billion while reducing patient wait times by 30%.', 'score': 0.66045773}, {'title': 'AI Diagnostics: Revolutionizing Medical Diagnosis in 2025 | Trends', 'url': 'https://www.scispot.com/blog/ai-diagnostics-revolutionizing-medical-diagnosis-in-2025', 'content': 'The implementation of AI-driven predictive analytics significantly improved patient care and healthcare outcomes. By analyzing historical data and identifying patterns, AI algorithms could forecast patient trajectories with high accuracy, enabling healthcare providers to intervene early, prevent complications, and tailor treatments based on individual patient profiles. [...] Looking ahead, advancements in machine learning, integration with wearable devices, personalized medicine, and autonomous diagnostic systems will continue to expand the possibilities of AI in diagnostic medicine. To stay competitive and deliver the best possible care in this rapidly evolving landscape, healthcare organizations must embrace AI diagnostic solutions that offer flexibility, scalability, and cutting-edge capabilities. [...] Artificial intelligence in medical diagnosis is transforming healthcare delivery, offering unprecedented levels of accuracy and efficiency. In 2025, AI diagnostics has evolved from an emerging technology to an essential component of modern healthcare systems. By leveraging machine learning and deep learning algorithms, AI diagnostic tools can process vast amounts of medical data swiftly and accurately, providing healthcare providers with invaluable insights for better patient care.', 'score': 0.6426349}, {'title': 'Improving triage performance in emergency departments using ...', 'url': 'https://bmcemergmed.biomedcentral.com/articles/10.1186/s12873-024-01135-2', 'content': '.\"), 39]. Another advanced method used in the field is Bidirectional Encoder Representations from Transformers (BERT), a model pre-trained on large text datasets, applied in patient triage prediction [45,46,47]. Recent studies have employed the Chat Generative Pre-trained Transformer (ChatGPT) model [48: A preliminary, scenario-based cross-sectional study. Turkish J Emerg Med. 2023;23(3):156. [...] Although AI models have great potential to support triage systems, recent studies, such as Zaboli et al.,  have shown that the current performance of models like ChatGPT is still inferior to that of nursing professionals in critical contexts. The study compared ChatGPT‚Äôs performance with that of nurses in assigning severity levels in 30 clinical cases. The results showed that the nurses achieved an AUROC of 0.910 (0.757‚Äì1.000), while ChatGPT presented an AUROC of 0.669 (0.153‚Äì1.000) in [...] adoption of XAI could increase confidence in the predictions of algorithms and provide insights into predictors that influence clinical outcomes, fostering better integration of AI into medical practice [52: Concepts, taxonomies, opportunities and challenges toward responsible AI,‚Äù Inf. Fusion, vol. 58, no. December 2019, pp. 82‚Äì115, Jun. 2020,', 'score': 0.44261298}, {'title': 'AI-Powered Triage Platform Could Aid Future Viral Outbreak ...', 'url': 'https://ysph.yale.edu/news-article/ai-powered-triage-platform-could-aid-future-viral-outbreak-response/', 'content': 'INFORMATION FOR\\n\\n# AI-Powered Triage Platform Could Aid Future Viral Outbreak Response\\n\\n# Artificial Intelligence and COVID-19\\n\\nA team of researchers from Yale University and other institutions globally has developed an innovative patient triage platform powered by artificial intelligence (AI) that the researchers say is capable of predicting patient disease severity and length of hospitalization during a viral outbreak. [...] \"Our AI-powered patient triage platform is distinct from typical COVID-19 AI prediction models,‚Äù said Georgia Charkoftaki, a lead author of the study and an associate research scientist in the Department of Environmental Health Sciences at YSPH. ‚ÄúIt serves as the cornerstone for a proactive and methodical approach to addressing upcoming viral outbreaks.\" [...] data-driven public health response.‚Äù', 'score': 0.4296453}, {'title': 'Tool Developed to Assist with Triage in the Emergency Department', 'url': 'https://www.hopkinsmedicine.org/news/articles/2022/11/tool-developed-to-assist-with-triage-in-the-emergency-department', 'content': '### New Tool Transforms Data Collection for Clinical Research\\n\\nSoftware translates data from electronic health records into a common open format, enabling researchers to quickly run queries across institutions without risking patient privacy.\\n\\nAn illustration represents sharing clinical data, thanks to Observational Medical Outcomes Partnership (OMOP).\\n\\n### Study Shows Johns Hopkins AI System Catches Sepsis Sooner [...] The technology is integrated into a patient‚Äôs digital health record. A nurse asks a patient for information about their condition and takes vital signs. The data, combined with the patient‚Äôs health care history, is run through the AI algorithm to predict the patient‚Äôs risk of several acute outcomes and to recommend a triage level of care, along with an explanation for the decision ‚Äî all in a matter of seconds. The nurse then assigns the triage level. [...] Johns Hopkins Medicine\\n\\n# News & Publications\\n\\n## News & Publications Main Menu\\n\\n# Tool Developed to Assist with Triage in the Emergency Department\\n\\nJohns Hopkins researchers thought they had developed an effective artificial intelligence (AI) tool that could help emergency department (ED) nurses decide the best approach for incoming patients. When they saw it in action in Johns Hopkins EDs, they felt validated.', 'score': 0.38588423}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [search]"
      ],
      "metadata": {
        "id": "QSvwHncQjl3W"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVg8XwxQjoj3",
        "outputId": "d3ed0af3-5c07-43ba-a4a3-8fa8a9371ae7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TavilySearchResults(api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********')))]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 3: Using Language Models"
      ],
      "metadata": {
        "id": "dWqojNWZjrCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \"langchain[mistralai]\""
      ],
      "metadata": {
        "id": "5TXjJIK7jrUe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "MISTRAL_API_KEY = \"Ip6BeFo1SfdytOJ0Nv04tLQ0WLXhygfT\"\n",
        "\n",
        "os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass(\"Enter API key for Mistral AI: \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQgqG92GjxrT",
        "outputId": "64f6f3ce-e77f-422a-85c6-c99234895f7c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter API key for Mistral AI: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "model = init_chat_model(\n",
        "    provider=\"mistralai\",\n",
        "    model=\"mistral-7b-instruct\",  # or your chosen Mistral model\n",
        "    api_key=os.environ[\"MISTRAL_API_KEY\"]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN5OlxQuj3tB",
        "outputId": "03d74e68-5a2d-4d48-bb71-2cf44966a758"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-54-3365882825.py:3: UserWarning: WARNING! provider is not default parameter.\n",
            "                provider was transferred to model_kwargs.\n",
            "                Please confirm that provider is what you intended.\n",
            "  model = init_chat_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "msg = HumanMessage(content=\"Tell me a fun fact about space exploration.\")"
      ],
      "metadata": {
        "id": "XCqC-FTij7uJ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_mistralai.chat_models import ChatMistralAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "import os\n",
        "\n",
        "# üîë Set your Mistral API key\n",
        "os.environ[\"MISTRAL_API_KEY\"] = \"DRtpspFMaJTRnCX5h16boN6Mi1okoAEa\"  # <-- replace with real key\n",
        "\n",
        "# ‚úÖ Use a valid model name\n",
        "model = ChatMistralAI(model=\"mistral-small-latest\")\n",
        "\n",
        "# üó®Ô∏è Create a message\n",
        "msg = HumanMessage(content=\"Tell me a fun fact about space exploration.\")\n",
        "\n",
        "# ‚úÖ Use .invoke()\n",
        "response = model.invoke([msg])\n",
        "\n",
        "# üñ®Ô∏è Print the response\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvM__2WGj9oW",
        "outputId": "20108c0e-a32d-4573-b8bb-ca95a8bffadd"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here‚Äôs a fun fact about space exploration:\n",
            "\n",
            "**The Voyager 1 spacecraft, launched in 1977, is the farthest human-made object from Earth and is currently in interstellar space‚Äîthe space between stars!** It carries a golden record with sounds and images of Earth, including greetings in 55 languages, music from different cultures, and even the sound of a kiss. If aliens ever find it, they‚Äôll get a cosmic mixtape from humanity!\n",
            "\n",
            "Bonus fact: Voyager 1‚Äôs power will run out around 2025, but it will keep drifting through the Milky Way for billions of years‚Äîlong after Earth is gone. üöÄ‚ú®\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 4: Tool Binding and Response Inspection"
      ],
      "metadata": {
        "id": "M_p1WeFBnZLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_tools = model.bind_tools(tools)"
      ],
      "metadata": {
        "id": "SrFwU-dwnZb_"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "# 1. Define a dummy tool (for example purposes)\n",
        "@tool\n",
        "def get_weather(location: str) -> str:\n",
        "    \"\"\"Returns the current weather for a given location.\"\"\"\n",
        "    return f\"The weather in {location} is sunny and 25¬∞C.\"\n",
        "\n",
        "# 2. List of tools\n",
        "tools = [get_weather]\n",
        "\n",
        "# 3. Bind tools to the model\n",
        "model_with_tools = model.bind_tools(tools)\n",
        "\n",
        "# 4. Use .invoke() instead of calling like a function\n",
        "response = model_with_tools.invoke([HumanMessage(content=\"What‚Äôs the weather like today in Paris?\")])\n",
        "\n",
        "# 5. Print response and tool call info\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNdMc0GCnbgm",
        "outputId": "0947ddb4-8d3d-457f-c324-d354ab7bdfdf"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ContentString: \n",
            "ToolCalls: [{'name': 'get_weather', 'args': {'location': 'Paris'}, 'id': 'at7gyRhmg', 'type': 'tool_call'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 5: Create the Agent"
      ],
      "metadata": {
        "id": "UzPQ7iicnuWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmgdVEYQn24O",
        "outputId": "2a7cbe05-b93f-48f7-d7b1-eba04b7350ca"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.72)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.1.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.6.0)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.2.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.4.8)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.11.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.0->langgraph) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent"
      ],
      "metadata": {
        "id": "rQqHJfYAnunS"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = create_react_agent(\n",
        "    model=model,     # ‚úÖ use 'model', not 'llm'\n",
        "    tools=tools\n",
        ")\n"
      ],
      "metadata": {
        "id": "a3nbs8LIn5ur"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(agent_executor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpI4swRUoDRZ",
        "outputId": "9fa002f4-4d9b-4eb9-f0a9-c290c033b723"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<langgraph.graph.state.CompiledStateGraph object at 0x7e0dae1f1910>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 7: Streaming Messages"
      ],
      "metadata": {
        "id": "Qkq5TfdYqKwq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "0c3Mvf8oqL-D"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [HumanMessage(content=\"Find the top 3 recent AI papers on medical imaging.\")]"
      ],
      "metadata": {
        "id": "HRoF2M3cqN4n"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stream_iterator = agent_executor.stream(\n",
        "    {\"messages\": messages},\n",
        "    stream_mode=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "id": "1tQ_OAgsqPzC"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in stream_iterator:\n",
        "    # Each step contains a list of messages; we print the first one\n",
        "    step[\"messages\"][0].pretty_print()"
      ],
      "metadata": {
        "id": "Y2uvWdZlqRvN"
      },
      "execution_count": 69,
      "outputs": []
    }
  ]
}