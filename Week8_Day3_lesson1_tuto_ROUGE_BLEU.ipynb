{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naomie25/DI-Bootcamp/blob/main/Week8_Day3_lesson1_tuto_ROUGE_BLEU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to implement BLEU in Python ?"
      ],
      "metadata": {
        "id": "eEFf8RwuxeTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Begin by importing the required modules:\n",
        "\n",
        "We import sqrt, log, and exp to perform fundamental mathematical operations‚Äîsquare-root extraction, natural logarithms, and exponentiation‚Äîand Counter to efficiently count and tally elements in iterable collections."
      ],
      "metadata": {
        "id": "fGqsTN2vxjJc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dnzk2BnzxPjZ"
      },
      "outputs": [],
      "source": [
        "from math import sqrt, log, exp\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the hypothesis and reference texts to establish the candidate output and its ground-truth comparisons, using examples drawn from David Bamman‚Äôs NLP23 repository.\n"
      ],
      "metadata": {
        "id": "-E3ML2joxl9Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hypothesis=\"Abandon all hope , ye who enter here\"\n",
        "references=[\"All hope abandon , ye who enter here\", \"All hope abandon , ye who enter in !\", \"Leave every hope, ye that enter\", \"Leave all hope , ye that enter\"]"
      ],
      "metadata": {
        "id": "1YUZALpsxksu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Then, we have to get the n-grams from the given text. We‚Äôll define a function to get the frequency of n-grams from the given text of size ‚Äúorder‚Äù.\n"
      ],
      "metadata": {
        "id": "tOkJrlqVxpw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the n-grams from the given text\n",
        "def get_ngrams(text, order):\n",
        "    \"\"\"\n",
        "    Given a string `text` and an integer `order`, returns a Counter object containing\n",
        "    the frequency counts of all ngrams of size `order` in the string.\n",
        "    \"\"\"\n",
        "    ngrams = Counter()\n",
        "\n",
        "    words = text.split()\n",
        "    for i in range(len(words)- order+1):\n",
        "      ngram = \" \". join(words[i: i + order])\n",
        "      ngrams[ngram] += 1\n",
        "\n",
        "    return ngrams"
      ],
      "metadata": {
        "id": "8quN46Vxxn6U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üöÄ Challenge : Print the n-grams!"
      ],
      "metadata": {
        "id": "H2RLVqs4xtRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let‚Äôs calculate bleu, which is done in four steps as clearly indicated in the code block below:"
      ],
      "metadata": {
        "id": "wtTJ1A7FxxK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_bleu(hypothesis, references):\n",
        "\n",
        "    bleu=0\n",
        "    p1=0\n",
        "    p2=0\n",
        "    p3=0\n",
        "    p4=0\n",
        "    bp=1\n",
        "\n",
        "    # 1. Find the closest reference to the hypothesis\n",
        "    closest_size=100000\n",
        "    closest_ref=[]\n",
        "\n",
        "    for ref in references:\n",
        "      ref_size = len(ref)\n",
        "      if abs(len(hypothesis) - ref_size) < closest_size:\n",
        "        closest_size = abs(len(hypothesis) - ref_size)\n",
        "        closest_ref = ref\n",
        "        pass\n",
        "\n",
        "    # 2. Calculating pn\n",
        "    pns=[]\n",
        "    for order in range(1,5):\n",
        "      # calculate intersection and union of n-grams\n",
        "      # hint: use the get_ngrams function you implemented\n",
        "      # calculate pn for each order\n",
        "        hyp_ngrams = get_ngrams(hypothesis, order)\n",
        "        hyp_count = Counter(hyp_ngrams)\n",
        "        closest_ref_ngrams = get_ngrams(closest_ref, order)\n",
        "        closest_ref_count = Counter(closest_ref_ngrams)\n",
        "        intersection_count = dict(hyp_count & closest_ref_count)\n",
        "        intersection_size = sum(intersection_count.values())\n",
        "        hyp_size = max(len(hyp_ngrams), 1)\n",
        "        p_n = intersection_size / hyp_size\n",
        "        pns.append(p_n)\n",
        "        pass\n",
        "\n",
        "    # 3. Calculating the brevity penalty\n",
        "    bp=1\n",
        "    c=len(hypothesis)\n",
        "    r=min(abs(len(ref) - c) for ref in references)\n",
        "    if c > r:\n",
        "      bp = 1.0\n",
        "    else:\n",
        "      bp = exp(1 - r / c)\n",
        "\n",
        "    # 4. Calculating the BLEU score\n",
        "    weights = [0.25] * 4\n",
        "    bleu=bp * exp(sum(w * log(p_n) for w, p_n in zip(weights, pns)))\n",
        "\n",
        "    # Assigning values to p1, p2, p3, p4!\n",
        "    p1, p2, p3, p4 = pns\n",
        "\n",
        "\n",
        "    # Do not change the variable name\n",
        "    return bleu, p1, p2, p3, p4, bp"
      ],
      "metadata": {
        "id": "jVtnBRunxvLy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final step? Calculate and print the bleu score. The value should be 0.5<bleu<1."
      ],
      "metadata": {
        "id": "eSoop0ftx1td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bleu, p1, p2, p3, p4, bp=calculate_bleu(hypothesis, references)\n",
        "print(\"BLEU: %.3f\" % bleu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGYO__z2xztq",
        "outputId": "4623fb97-bf5e-43c8-a5f4-818fcc6a5353"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU: 0.541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üöÄ Challenge : What was the bleu value ? What does it indicate?"
      ],
      "metadata": {
        "id": "un6ATIMqx53W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How to implement it in Python : Computing ROUGE Scores in Python"
      ],
      "metadata": {
        "id": "5Z17ndkXx7N1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will follow a step-by-step tutorial for computing ROUGE-N and ROUGE-L metrics. You can also follow this [colab](https://colab.research.google.com/drive/1yU9Hwg356TdLUONB4ozuQ72H9DauXQLh)\n",
        "\n",
        "#### 1. Imports and Example Texts\n",
        "\n",
        "We‚Äôll reuse `Counter` for n-grams and implement our own LCS routine:"
      ],
      "metadata": {
        "id": "Kt8Jd9UNyAhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "hypothesis = \"Abandon all hope , ye who enter here\"\n",
        "references = [\n",
        "    \"All hope abandon , ye who enter here\",\n",
        "    \"All hope abandon , ye who enter in !\",\n",
        "    \"Leave every hope, ye that enter\",\n",
        "    \"Leave all hope , ye that enter\"\n",
        "]"
      ],
      "metadata": {
        "id": "D0DOp7ETx-4d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. N-gram Extraction"
      ],
      "metadata": {
        "id": "jBnq2cT0yC7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ngrams(text, order):\n",
        "    \"\"\"\n",
        "    Returns a Counter of all n-grams of size `order` in `text`.\n",
        "    \"\"\"\n",
        "    ngrams = Counter()\n",
        "    words = text.split()\n",
        "    for i in range(len(words) - order + 1):\n",
        "        ngram = \" \".join(words[i : i + order])\n",
        "        ngrams[ngram] += 1\n",
        "    return ngrams"
      ],
      "metadata": {
        "id": "amhTtHl_yEII"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üöÄ **Challenge**: Print the 1- and 2-grams of the hypothesis!"
      ],
      "metadata": {
        "id": "tr3xqjywyIU7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. ROUGE-N (Recall, Precision, F‚ÇÅ)\n",
        "\n",
        "For each n (e.g., 1, 2), compute:\n",
        "\n",
        "* **Recall** = overlap\\_ngrams / total\\_ngrams\\_in\\_reference\n",
        "* **Precision** = overlap\\_ngrams / total\\_ngrams\\_in\\_hypothesis\n",
        "* **F‚ÇÅ** = 2 √ó P √ó R / (P + R)\n",
        "\n",
        "Average over references by taking the maximum overlap against any single reference."
      ],
      "metadata": {
        "id": "1wEeO6lVyKBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rouge_n(hyp, refs, n):\n",
        "    \"\"\"\n",
        "    Compute ROUGE-N (recall, precision, f1) for one hypothesis vs. multiple references.\n",
        "    \"\"\"\n",
        "    hyp_ngrams = get_ngrams(hyp, n)\n",
        "    best = {\"overlap\": 0, \"ref_count\": 0}\n",
        "\n",
        "    for ref in refs:\n",
        "        ref_ngrams = get_ngrams(ref, n)\n",
        "        overlap = sum((hyp_ngrams & ref_ngrams).values())\n",
        "        if overlap > best[\"overlap\"]:\n",
        "            best[\"overlap\"] = overlap\n",
        "            best[\"ref_count\"] = sum(ref_ngrams.values())\n",
        "\n",
        "    hyp_count = sum(hyp_ngrams.values())\n",
        "    recall    = best[\"overlap\"] / best[\"ref_count\"] if best[\"ref_count\"] > 0 else 0.0\n",
        "    precision = best[\"overlap\"] / hyp_count         if hyp_count > 0        else 0.0\n",
        "    f1 = (2 * precision * recall / (precision + recall)\n",
        "          if (precision + recall) > 0 else 0.0)\n",
        "\n",
        "    return recall, precision, f1"
      ],
      "metadata": {
        "id": "g2OC1RamyFn0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. ROUGE-L (Longest Common Subsequence)\n",
        "\n",
        "ROUGE-L uses the LCS length between hypothesis and reference:\n",
        "\n",
        "* **Recall** = LCS / |reference|\n",
        "* **Precision** = LCS / |hypothesis|\n",
        "* **F‚ÇÅ** = (1 + Œ≤¬≤)¬∑P¬∑R / (R + Œ≤¬≤¬∑P), with Œ≤ = 1 by default.\n"
      ],
      "metadata": {
        "id": "KxZv-D9GyOKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _lcs_length(a, b):\n",
        "    \"\"\"Compute length of LCS between sequences a and b via dynamic programming.\"\"\"\n",
        "    m, n = len(a), len(b)\n",
        "    dp = [[0]*(n+1) for _ in range(m+1)]\n",
        "    for i in range(m):\n",
        "        for j in range(n):\n",
        "            if a[i] == b[j]:\n",
        "                dp[i+1][j+1] = dp[i][j] + 1\n",
        "            else:\n",
        "                dp[i+1][j+1] = max(dp[i][j+1], dp[i+1][j])\n",
        "    return dp[m][n]\n",
        "\n",
        "\n",
        "def rouge_l(hyp, refs, beta=1.0):\n",
        "    \"\"\"\n",
        "    Compute ROUGE-L (recall, precision, f1) for one hypothesis vs. multiple references.\n",
        "    Takes the reference yielding the highest F1.\n",
        "    \"\"\"\n",
        "    best = {\"f1\": 0, \"r\": 0, \"p\": 0}\n",
        "    hyp_tokens = hyp.split()\n",
        "\n",
        "    for ref in refs:\n",
        "        ref_tokens = ref.split()\n",
        "        lcs = _lcs_length(hyp_tokens, ref_tokens)\n",
        "        r = lcs / len(ref_tokens) if ref_tokens else 0.0\n",
        "        p = lcs / len(hyp_tokens)   if hyp_tokens else 0.0\n",
        "        denom = r + (beta**2) * p\n",
        "        f1 = ((1 + beta**2) * p * r / denom) if denom > 0 else 0.0\n",
        "\n",
        "        if f1 > best[\"f1\"]:\n",
        "            best.update({\"f1\": f1, \"r\": r, \"p\": p})\n",
        "\n",
        "    return best[\"r\"], best[\"p\"], best[\"f1\"]"
      ],
      "metadata": {
        "id": "RTQI3qwEyMFA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute and print ROUGE-1, ROUGE-2, and ROUGE-L on our example:"
      ],
      "metadata": {
        "id": "0WeqlcLnyR-l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ROUGE-1\n",
        "r1, p1, f1 = rouge_n(hypothesis, references, 1)\n",
        "print(f\"ROUGE-1 ‚Üí recall: {r1:.3f}, precision: {p1:.3f}, F1: {f1:.3f}\")\n",
        "\n",
        "# ROUGE-2\n",
        "r2, p2, f2 = rouge_n(hypothesis, references, 2)\n",
        "print(f\"ROUGE-2 ‚Üí recall: {r2:.3f}, precision: {p2:.3f}, F1: {f2:.3f}\")\n",
        "\n",
        "# ROUGE-L\n",
        "rl_r, rl_p, rl_f1 = rouge_l(hypothesis, references)\n",
        "print(f\"ROUGE-L ‚Üí recall: {rl_r:.3f}, precision: {rl_p:.3f}, F1: {rl_f1:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4GOeQeSyQeV",
        "outputId": "f574e708-0a13-4088-8b45-89af29856e1f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE-1 ‚Üí recall: 0.750, precision: 0.750, F1: 0.750\n",
            "ROUGE-2 ‚Üí recall: 0.571, precision: 0.571, F1: 0.571\n",
            "ROUGE-L ‚Üí recall: 0.750, precision: 0.750, F1: 0.750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YqC5DI-JyTuM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}