{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPk8j0rwwokTgPNqvAf8G5k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naomie25/DI-Bootcamp/blob/main/Week8_Day3_ExerciceXP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part I. Setup"
      ],
      "metadata": {
        "id": "Bi4l7fyigDHl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Gdr4Rs_fBDa",
        "outputId": "208ce56d-9824-4884-bc11-1facc2b1bd55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rouge_score==0.1.2 in /usr/local/lib/python3.11/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score==0.1.2) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score==0.1.2) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score==0.1.2) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score==0.1.2) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score==0.1.2) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score==0.1.2) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score==0.1.2) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score==0.1.2) (4.67.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.5)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.15)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.11.1->datasets) (2025.3.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.33.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->datasets) (2025.7.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge_score==0.1.2\n",
        "!pip install evaluate\n",
        "!pip install -U accelerate --quiet\n",
        "!pip install datasets\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lfy1IbZgxAx",
        "outputId": "94900b87-8318-43b2-d416-0a1edaf9fe88"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part II : Dataset Loading and Exploration"
      ],
      "metadata": {
        "id": "EXMTxzSFg9eP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load datasets\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "\n",
        "train_sample = train_df.sample(n=100, random_state=42)\n",
        "test_sample = test_df.sample(n=50, random_state=42)\n",
        "\n",
        "# Display first example (show full row of features)\n",
        "print(\"üî∑ First Example from Train Sample:\")\n",
        "print(train_sample.iloc[0])\n",
        "\n",
        "# Inspect DataFrames\n",
        "print(\"\\n Sampled Train DataFrame:\\n\", train_sample.head())\n",
        "print(\"\\n Sampled Test DataFrame:\\n\", test_sample.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lp30hhUng9vZ",
        "outputId": "c93b2389-bce2-4823-b2ad-091d7a2b2fd9"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üî∑ First Example from Train Sample:\n",
            "battery_power    1646.0\n",
            "blue                0.0\n",
            "clock_speed         2.5\n",
            "dual_sim            0.0\n",
            "fc                  3.0\n",
            "four_g              1.0\n",
            "int_memory         25.0\n",
            "m_dep               0.6\n",
            "mobile_wt         200.0\n",
            "n_cores             2.0\n",
            "pc                  5.0\n",
            "px_height         211.0\n",
            "px_width         1608.0\n",
            "ram               686.0\n",
            "sc_h                8.0\n",
            "sc_w                6.0\n",
            "talk_time          11.0\n",
            "three_g             1.0\n",
            "touch_screen        1.0\n",
            "wifi                0.0\n",
            "price_range         0.0\n",
            "Name: 1860, dtype: float64\n",
            "\n",
            " Sampled Train DataFrame:\n",
            "       battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
            "1860           1646     0          2.5         0   3       1          25   \n",
            "353            1182     0          0.5         0   7       1           8   \n",
            "1333           1972     0          2.9         0   9       0          14   \n",
            "905             989     1          2.0         0   4       0          17   \n",
            "1289            615     1          0.5         1   7       0          58   \n",
            "\n",
            "      m_dep  mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  \\\n",
            "1860    0.6        200        2  ...        211      1608   686     8     6   \n",
            "353     0.5        138        8  ...        275       986  2563    19    17   \n",
            "1333    0.4        196        7  ...        293       952  1316     8     1   \n",
            "905     0.2        166        3  ...        256      1394  3892    18     7   \n",
            "1289    0.5        130        5  ...       1021      1958  1906    14     5   \n",
            "\n",
            "      talk_time  three_g  touch_screen  wifi  price_range  \n",
            "1860         11        1             1     0            0  \n",
            "353          19        1             0     0            2  \n",
            "1333          8        1             1     0            1  \n",
            "905          19        1             1     0            3  \n",
            "1289          5        1             0     0            1  \n",
            "\n",
            "[5 rows x 21 columns]\n",
            "\n",
            " Sampled Test DataFrame:\n",
            "       id  battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
            "521  522            756     0          1.0         0   0       0          33   \n",
            "737  738           1341     0          1.4         0   8       1          38   \n",
            "740  741           1803     1          2.6         0   7       1           9   \n",
            "660  661           1023     1          2.8         1  16       0          44   \n",
            "411  412           1745     0          1.8         0   0       0          45   \n",
            "\n",
            "     m_dep  mobile_wt  ...  pc  px_height  px_width   ram  sc_h  sc_w  \\\n",
            "521    0.2        177  ...   3        506       573  3402    19     0   \n",
            "737    1.0        170  ...  10        601       937  1579    16     4   \n",
            "740    0.9        112  ...  12        156      1289   406     9     3   \n",
            "660    0.7        176  ...  17        629      1158  1830    14    11   \n",
            "411    0.1        110  ...   2       1070      1445  2352    11     9   \n",
            "\n",
            "     talk_time  three_g  touch_screen  wifi  \n",
            "521          3        1             1     0  \n",
            "737         19        1             0     1  \n",
            "740          5        1             0     0  \n",
            "660          6        0             0     0  \n",
            "411         16        1             0     1  \n",
            "\n",
            "[5 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part III : Summarization with T5"
      ],
      "metadata": {
        "id": "Z-fE2K5KjJBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "import pandas as pd\n",
        "from transformers import T5ForConditionalGeneration, AutoTokenizer"
      ],
      "metadata": {
        "id": "3yXdf5lMjGkw"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_generator(items, batch_size):\n",
        "    for i in range(0, len(items), batch_size):\n",
        "        yield items[i:i + batch_size]"
      ],
      "metadata": {
        "id": "Cbmduwj-jsyy"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_with_t5(articles, model, tokenizer, batch_size=8, device=None):\n",
        "    if device is None:\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    model = model.to(device)\n",
        "    summaries = []\n",
        "\n",
        "    for batch in batch_generator(articles, batch_size):\n",
        "        inputs = [\"summarize: \" + text for text in batch]\n",
        "        encoding = tokenizer(\n",
        "            inputs,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **encoding,\n",
        "                max_length=150,\n",
        "                num_beams=4,\n",
        "                early_stopping=True\n",
        "            )\n",
        "\n",
        "        decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "        summaries.extend(decoded)\n",
        "\n",
        "        # Free memory after each batch\n",
        "        del encoding, outputs\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    # Final cleanup\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    return summaries\n"
      ],
      "metadata": {
        "id": "ixoqGBplkK88"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, T5ForConditionalGeneration\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
      ],
      "metadata": {
        "id": "QGYhN9fukMsm"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Combine features into text to simulate summarization input\n",
        "articles = train_sample.astype(str).apply(lambda row: \" \".join(row.values), axis=1).tolist()\n",
        "\n",
        "# Generate summaries\n",
        "generated_summaries = summarize_with_t5(articles, model, tokenizer, batch_size=8)"
      ],
      "metadata": {
        "id": "DbfyHrJTmznr"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame({\n",
        "    'Input_Features': articles,\n",
        "    'Generated_Summary': generated_summaries,\n",
        "    'Reference_Price_Class': train_sample['price_range'].values\n",
        "})\n",
        "\n",
        "# Display\n",
        "print(results_df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnntpfrunBtx",
        "outputId": "c62ea0d3-87fa-4f16-c7c8-e162bc6ce8d5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      Input_Features  \\\n",
            "0  1646 0 2.5 0 3 1 25 0.6 200 2 5 211 1608 686 8...   \n",
            "1  1182 0 0.5 0 7 1 8 0.5 138 8 16 275 986 2563 1...   \n",
            "2  1972 0 2.9 0 9 0 14 0.4 196 7 18 293 952 1316 ...   \n",
            "3  989 1 2.0 0 4 0 17 0.2 166 3 19 256 1394 3892 ...   \n",
            "4  615 1 0.5 1 7 0 58 0.5 130 5 8 1021 1958 1906 ...   \n",
            "5  627 1 1.6 1 3 1 12 0.2 131 7 17 447 819 2476 1...   \n",
            "6  894 0 0.9 0 5 1 54 0.2 130 3 15 104 541 2829 1...   \n",
            "7  1066 0 3.0 1 6 1 5 0.5 167 5 7 53 1504 1044 8 ...   \n",
            "8  616 0 1.9 1 13 1 44 0.8 81 3 17 651 1618 3366 ...   \n",
            "9  712 0 0.5 0 6 0 27 0.5 86 2 11 1245 1309 2001 ...   \n",
            "\n",
            "                                   Generated_Summary  Reference_Price_Class  \n",
            "0  1646 0 2.5 0 3 1 25 0.6 200 2 5 211 1608 686 8...                      0  \n",
            "1  1182 0 0.5 0 7 1 8 0.5 138 8 16 275 986 2563 1...                      2  \n",
            "2     1972 0 2.9 0 9 0 14 0.4 196 7 18 293 952 1316.                      1  \n",
            "3  989 1 2.0 0 4 0 17 0.2 166 3 19 256 1394 3892 ...                      3  \n",
            "4  615 1 0.5 1 7 0 58 0.5 130 5 8 1021 1958 1906 ...                      1  \n",
            "5  627 1 1.6 1 3 1 12 0.2 131 7 17 447 819 2476 1...                      1  \n",
            "6  894 0 0.9 0 5 1 54 0.2 130 3 15 104 541 2829 1...                      2  \n",
            "7  1066 0 3.0 1 6 1 5 0.5 167 5 7 53 1504 1044 8 ...                      0  \n",
            "8  616 0 1.9 1 13 1 44 0.8 81 3 17 651 1618 3366 ...                      3  \n",
            "9  712 0 0.5 0 6 0 27 0.5 86 2 11 1245 1309 2001 ...                      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part IV : Accuracy Evaluation"
      ],
      "metadata": {
        "id": "m8Du9S2goqgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Simplified comparison: if generated summary exactly matches the price class (as string)\n",
        "generated_predictions = [summary.strip() for summary in generated_summaries]\n",
        "reference_labels = [str(label) for label in train_sample['price_range'].values]\n",
        "\n",
        "# Calculate exact match accuracy\n",
        "accuracy = accuracy_score(reference_labels, generated_predictions)\n",
        "\n",
        "print(f\"Accuracy of T5-small summaries: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-B3SKe_oohd",
        "outputId": "d88ce02b-e81e-475c-b843-681adb237c6a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of T5-small summaries: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An accuracy of 0.0000 confirms what we anticipated:\n",
        "\n",
        "‚û°Ô∏è T5-small is not predicting your price_range classes correctly, simply because it‚Äôs not designed for classification but for text generation/summarization.\n",
        "\n"
      ],
      "metadata": {
        "id": "vyayMA8Po-jM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part V : ROUGE Metric Implementation"
      ],
      "metadata": {
        "id": "Tt94LguNsr10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "import nltk\n",
        "\n",
        "# Load ROUGE metric\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "# Download NLTK punkt tokenizer (for sentence splitting)\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBoy2ntLpasq",
        "outputId": "40dd2289-8fd1-42c7-81fe-a604c46b445f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "def compute_rouge_score(predictions, references):\n",
        "    # Preprocess by adding newline between sentences\n",
        "    predictions = [\"\\n\".join(sent_tokenize(pred)) for pred in predictions]\n",
        "    references = [\"\\n\".join(sent_tokenize(ref)) for ref in references]\n",
        "\n",
        "    # Compute ROUGE scores\n",
        "    results = rouge.compute(predictions=predictions, references=references)\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "L6Ce51y0sPI_"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example reference and generated summaries\n",
        "refs = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"Machine learning is great for text summarization.\"\n",
        "]\n",
        "\n",
        "preds = [\n",
        "    \"The brown fox jumps over the dog.\",\n",
        "    \"ML is useful for summarizing text.\"\n",
        "]\n",
        "\n",
        "scores = compute_rouge_score(preds, refs)\n",
        "print(scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0WEKS0VsSMq",
        "outputId": "0a135663-5ff5-4839-de77-78d704f349f0"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rouge1': np.float64(0.6682692307692308), 'rouge2': np.float64(0.28571428571428575), 'rougeL': np.float64(0.6682692307692308), 'rougeLsum': np.float64(0.6682692307692308)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part VI : Understanding ROUGE Scores"
      ],
      "metadata": {
        "id": "ueVgRdeLsm3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "refs = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"Machine learning is great for text summarization.\"\n",
        "]\n",
        "\n",
        "preds = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"Machine learning is great for text summarization.\"\n",
        "]\n",
        "\n",
        "scores = compute_rouge_score(preds, refs)\n",
        "print(\"Exact Match ROUGE Scores:\", scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjOafhmIsnMW",
        "outputId": "ff9396fb-c69c-42ed-b3e1-2c0810ca5b12"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exact Match ROUGE Scores: {'rouge1': np.float64(1.0), 'rouge2': np.float64(1.0), 'rougeL': np.float64(1.0), 'rougeLsum': np.float64(1.0)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Null prediction\n",
        "preds = [\"\", \"\"]\n",
        "\n",
        "scores = compute_rouge_score(preds, refs)\n",
        "print(\"Null Prediction ROUGE Scores:\", scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEX9GsXCs7cm",
        "outputId": "6b36ac76-ea7f-416f-c80a-d8f67abbe9e8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null Prediction ROUGE Scores: {'rouge1': np.float64(0.0), 'rouge2': np.float64(0.0), 'rougeL': np.float64(0.0), 'rougeLsum': np.float64(0.0)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Stemming Effect\n",
        "refs = [\"The cat is running in the park.\"]\n",
        "preds_no_stem = [\"The cat is run in the park.\"]  # Different word form, same meaning\n",
        "\n",
        "scores = compute_rouge_score(preds_no_stem, refs)\n",
        "print(\"ROUGE with stemming (default):\", scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KMxBUbIs_S3",
        "outputId": "02f1f176-9aa1-4c01-edeb-e6b64a1c8ce9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE with stemming (default): {'rouge1': np.float64(0.8571428571428571), 'rouge2': np.float64(0.6666666666666666), 'rougeL': np.float64(0.8571428571428571), 'rougeLsum': np.float64(0.8571428571428571)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# N-grams\n",
        "refs = [\"The quick brown fox jumps over the lazy dog.\"]\n",
        "\n",
        "# Different predictions\n",
        "preds_list = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",  # full overlap\n",
        "    \"The brown fox jumps over the dog.\",             # partial overlap\n",
        "    \"Fox jumps over lazy.\",                           # less overlap\n",
        "    \"Cat runs fast.\"                                  # no overlap\n",
        "]\n",
        "\n",
        "for pred in preds_list:\n",
        "    score = compute_rouge_score([pred], refs)\n",
        "    print(f\"Prediction: {pred}\\nROUGE scores: {score}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoPzzfggtDEu",
        "outputId": "a4681649-bfa4-466f-b3a3-9bc9fdbab5db"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: The quick brown fox jumps over the lazy dog.\n",
            "ROUGE scores: {'rouge1': np.float64(1.0), 'rouge2': np.float64(1.0), 'rougeL': np.float64(1.0), 'rougeLsum': np.float64(1.0)}\n",
            "\n",
            "Prediction: The brown fox jumps over the dog.\n",
            "ROUGE scores: {'rouge1': np.float64(0.8750000000000001), 'rouge2': np.float64(0.5714285714285715), 'rougeL': np.float64(0.8750000000000001), 'rougeLsum': np.float64(0.8750000000000001)}\n",
            "\n",
            "Prediction: Fox jumps over lazy.\n",
            "ROUGE scores: {'rouge1': np.float64(0.6153846153846153), 'rouge2': np.float64(0.36363636363636365), 'rougeL': np.float64(0.6153846153846153), 'rougeLsum': np.float64(0.6153846153846153)}\n",
            "\n",
            "Prediction: Cat runs fast.\n",
            "ROUGE scores: {'rouge1': np.float64(0.0), 'rouge2': np.float64(0.0), 'rougeL': np.float64(0.0), 'rougeLsum': np.float64(0.0)}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "refs = [\"The quick brown fox jumps over the lazy dog.\"]\n",
        "preds = [\"The brown fox jumps.\"]\n",
        "\n",
        "score1 = compute_rouge_score(preds, refs)\n",
        "score2 = compute_rouge_score(refs, preds)\n",
        "\n",
        "print(\"ROUGE(preds, refs):\", score1)\n",
        "print(\"ROUGE(refs, preds):\", score2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beMA6q8RtQFa",
        "outputId": "498bb0d9-9697-4279-933f-9a5288a1cf29"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE(preds, refs): {'rouge1': np.float64(0.6153846153846153), 'rouge2': np.float64(0.36363636363636365), 'rougeL': np.float64(0.6153846153846153), 'rougeLsum': np.float64(0.6153846153846153)}\n",
            "ROUGE(refs, preds): {'rouge1': np.float64(0.6153846153846153), 'rouge2': np.float64(0.36363636363636365), 'rougeL': np.float64(0.6153846153846153), 'rougeLsum': np.float64(0.6153846153846153)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part VII : Comparing Small and Large Models"
      ],
      "metadata": {
        "id": "50HtbzQftxMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import gc\n",
        "import pandas as pd\n",
        "from transformers import T5ForConditionalGeneration, AutoTokenizer, GPT2Tokenizer, GPT2LMHeadModel\n",
        "import evaluate\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "rouge = evaluate.load(\"rouge\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQOifgB3tyYR",
        "outputId": "71bf5b0e-7219-47df-d75b-b98d73688645"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rouge functions\n",
        "def preprocess_summaries(summaries):\n",
        "    return [\"\\n\".join(sent_tokenize(s)) for s in summaries]\n",
        "\n",
        "def compute_rouge_score(predictions, references):\n",
        "    predictions = preprocess_summaries(predictions)\n",
        "    references = preprocess_summaries(references)\n",
        "    return rouge.compute(predictions=predictions, references=references)\n",
        "\n",
        "def compute_rouge_per_row(preds, refs):\n",
        "    \"\"\"Compute ROUGE scores for each prediction-reference pair.\"\"\"\n",
        "    results = []\n",
        "    for p, r in zip(preds, refs):\n",
        "        score = rouge.compute(predictions=[p], references=[r])\n",
        "        results.append(score)\n",
        "    return pd.DataFrame(results)\n"
      ],
      "metadata": {
        "id": "7fYBL8Aht39L"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summarize with T5\n",
        "def summarize_with_t5(articles, model_name=\"t5-small\", batch_size=8, max_length=150):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "    summaries = []\n",
        "    for i in range(0, len(articles), batch_size):\n",
        "        batch = articles[i:i+batch_size]\n",
        "        inputs = [\"summarize: \" + text for text in batch]\n",
        "        encoding = tokenizer(\n",
        "            inputs,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=512\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **encoding,\n",
        "                max_length=max_length,\n",
        "                num_beams=4,\n",
        "                early_stopping=True\n",
        "            )\n",
        "        decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "        summaries.extend(decoded)\n",
        "\n",
        "        del encoding, outputs\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "    return summaries\n"
      ],
      "metadata": {
        "id": "CZrv4Ytnt6M0"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_with_gpt2(articles, batch_size=8, max_length=100):\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    model_name = \"gpt2\"\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "    model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
        "\n",
        "    summaries = []\n",
        "    for i in range(0, len(articles), batch_size):\n",
        "        batch = articles[i:i+batch_size]\n",
        "        for text in batch:\n",
        "            prompt = text.strip() + \"\\nTL;DR:\"\n",
        "            inputs = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
        "\n",
        "            # GPT2 has max length limits (usually 1024 tokens)\n",
        "            max_gen_len = min(max_length, 1024 - inputs.size(1))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model.generate(\n",
        "                    inputs,\n",
        "                    max_length=inputs.size(1) + max_gen_len,\n",
        "                    do_sample=False,\n",
        "                    num_beams=4,\n",
        "                    no_repeat_ngram_size=3,\n",
        "                    early_stopping=True\n",
        "                )\n",
        "            generated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "            # Extract summary after \"TL;DR:\"\n",
        "            summary = generated.split(\"TL;DR:\")[-1].strip()\n",
        "            summaries.append(summary)\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "    return summaries\n"
      ],
      "metadata": {
        "id": "vm14CrxiuAjk"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_models(rouge_scores_dict):\n",
        "    \"\"\"\n",
        "    Aggregate average ROUGE scores from different models into a single DataFrame.\n",
        "\n",
        "    Args:\n",
        "        rouge_scores_dict (dict): {model_name: {rouge_type: score, ...}, ...}\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Aggregated ROUGE scores.\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    for model_name, scores in rouge_scores_dict.items():\n",
        "        row = {'Model': model_name}\n",
        "        row.update(scores)\n",
        "        rows.append(row)\n",
        "    return pd.DataFrame(rows)\n",
        "\n"
      ],
      "metadata": {
        "id": "A0EC2WVsuDGg"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_models_summaries(summaries_dict, references, sample_count=5):\n",
        "    df = pd.DataFrame({'Reference Summary': references})\n",
        "    for model_name, summaries in summaries_dict.items():\n",
        "        df[f\"{model_name} Summary\"] = summaries\n",
        "    return df.head(sample_count)\n"
      ],
      "metadata": {
        "id": "ay1puru75Qoi"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example dictionaries\n",
        "rouge_scores_dict = {\n",
        "    't5-small': rouge_small,\n",
        "    't5-base': rouge_base,\n",
        "    'gpt2': rouge_gpt2\n",
        "}\n",
        "\n",
        "summaries_dict = {\n",
        "    't5-small': summaries_small,\n",
        "    't5-base': summaries_base,\n",
        "    'gpt2': summaries_gpt2\n",
        "}\n",
        "\n",
        "# Generate aggregated ROUGE table\n",
        "rouge_df = compare_models(rouge_scores_dict)\n",
        "print(\"\\nüìä Aggregated ROUGE Scores:\")\n",
        "print(rouge_df)\n",
        "\n",
        "# Generate side-by-side summary comparison\n",
        "summaries_df = compare_models_summaries(summaries_dict, references, sample_count=5)\n",
        "print(\"\\nüìë Side-by-Side Summary Comparison:\")\n",
        "print(summaries_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "058tlqyI5U_o",
        "outputId": "c884c7b4-9bee-4ce2-cc4e-52ffb9f24559"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Aggregated ROUGE Scores:\n",
            "      Model    rouge1  rouge2    rougeL  rougeLsum\n",
            "0  t5-small  0.056458     0.0  0.056655   0.056639\n",
            "1   t5-base  0.085246     0.0  0.085376   0.085406\n",
            "2      gpt2  0.000440     0.0  0.000523   0.000523\n",
            "\n",
            "üìë Side-by-Side Summary Comparison:\n",
            "  Reference Summary                                   t5-small Summary  \\\n",
            "0                 0  1646 0 2.5 0 3 1 25 0.6 200 2 5 211 1608 686 8...   \n",
            "1                 2  1182 0 0.5 0 7 1 8 0.5 138 8 16 275 986 2563 1...   \n",
            "2                 1     1972 0 2.9 0 9 0 14 0.4 196 7 18 293 952 1316.   \n",
            "3                 3  989 1 2.0 0 4 0 17 0.2 166 3 19 256 1394 3892 ...   \n",
            "4                 1  615 1 0.5 1 7 0 58 0.5 130 5 8 1021 1958 1906 ...   \n",
            "\n",
            "                                     t5-base Summary  \\\n",
            "0  1646 0 2.5 0 3 1 25 0.6 200 2 5 211 1608 686 8...   \n",
            "1  0 0 0 7 1 8 0.5 138 8 16 275 986 2563 19 17 19...   \n",
            "2  0 2.9 0 9 0 14 0.4 196 7 18 293 952 1316 8 1 8...   \n",
            "3  989 1 2.0 0 4 0 17 0.2 166 3 19 256 1394 3892 ...   \n",
            "4  58 0.5 130 5 8 1021 1958 1906 14 5 5 1 0 0 1 0...   \n",
            "\n",
            "                                        gpt2 Summary  \n",
            "0  If you're looking for a quick and easy way to ...  \n",
            "1  If you're looking for a quick and easy way to ...  \n",
            "2  If you're looking for a quick and easy way to ...  \n",
            "3  This is a good example of how to build a simpl...  \n",
            "4  This is a very good example of how to make a g...  \n"
          ]
        }
      ]
    }
  ]
}