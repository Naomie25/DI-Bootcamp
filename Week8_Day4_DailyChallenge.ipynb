{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyObNRadIILDu2KdvWBTQW41",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naomie25/DI-Bootcamp/blob/main/Week8_Day4_DailyChallenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import random\n",
        "import string\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import BertConfig\n",
        "from transformers.models.bert.modeling_bert import BertEncoder\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "metadata": {
        "id": "pEHj7GnNBFUU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "I_RH0ZEJBf2B"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = \"/content/train_essays.csv\"\n",
        "TEST_PATH = \"/content/test_essays.csv\"\n",
        "PROMPT_PATH = \"/content/train_prompts.csv\"\n",
        "\n",
        "src_train = pd.read_csv(TRAIN_PATH)\n",
        "src_prompt = pd.read_csv(PROMPT_PATH)\n",
        "src_test=pd.read_csv(TEST_PATH)\n",
        "#src_sub = TODO"
      ],
      "metadata": {
        "id": "WJTKi9NtCSp6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "b8BecqSWCm9I",
        "outputId": "49d1a742-caa5-4b60-9184-7392e8440144"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id  prompt_id                                               text  \\\n",
              "0  0059830c          0  Cars. Cars have been around since they became ...   \n",
              "1  005db917          0  Transportation is a large necessity in most co...   \n",
              "2  008f63e3          0  \"America's love affair with it's vehicles seem...   \n",
              "3  00940276          0  How often do you ride in a car? Do you drive a...   \n",
              "4  00c39458          0  Cars are a wonderful thing. They are perhaps o...   \n",
              "\n",
              "   generated  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  \n",
              "3          0  \n",
              "4          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b660ba7-8c97-4655-b5dd-d26d07d656c6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>generated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0059830c</td>\n",
              "      <td>0</td>\n",
              "      <td>Cars. Cars have been around since they became ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>005db917</td>\n",
              "      <td>0</td>\n",
              "      <td>Transportation is a large necessity in most co...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>008f63e3</td>\n",
              "      <td>0</td>\n",
              "      <td>\"America's love affair with it's vehicles seem...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00940276</td>\n",
              "      <td>0</td>\n",
              "      <td>How often do you ride in a car? Do you drive a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00c39458</td>\n",
              "      <td>0</td>\n",
              "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b660ba7-8c97-4655-b5dd-d26d07d656c6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2b660ba7-8c97-4655-b5dd-d26d07d656c6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2b660ba7-8c97-4655-b5dd-d26d07d656c6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-84dc7147-48fc-474c-8a7a-35d53570705d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-84dc7147-48fc-474c-8a7a-35d53570705d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-84dc7147-48fc-474c-8a7a-35d53570705d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "src_train",
              "summary": "{\n  \"name\": \"src_train\",\n  \"rows\": 1378,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1378,\n        \"samples\": [\n          \"70d7c567\",\n          \"81977e6c\",\n          \"e43869b8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prompt_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1378,\n        \"samples\": [\n          \"Can you imagine living in a place where there is no driving? It is an amazing thing to think if every person doesn't drive in one big city that it saves so much pollution going in to the air. Another thing to think about is if everyone in a city didn't drive and walked everywhere, more people would stay healthier by staying in shape. Some people think that owning a car is more stressful than just walking everywhere. If you don't own a car you don't have to pay for insurance, don't have to pay for gas, and don't have to pay for repairs when something goes wrong in a vehicle. To me it sounds like there is a lot of advantages in limiting car use.\\n\\nOne solid reason why not using cars as much is the pollution going in the air. In Paris, France motorists with even numbered license plates were ordered to leave their cars at their house or else they would be fined. The next day odd numbered license plates motorists had to leave their vehicles at home. It was a hardship at first to get people to follow these new rules, but after about five days everything started to cool down. The pollution had dropped 60 percent in Paris which is exactly what the city was looking for. Limiting the car usage didn't just save pollution from going in the air, but also there wasn't as much traffic as there usually was. It also made Paris a safer place to be outside and not damage the citizens lungs. The capital city of France also made transportation free MondayFriday to help the cause. Soon enough people that had both license plates could drive on the same day.\\n\\nIn Bogota, Colombia they do a car free day that is becoming popular in that part of the world. It is awesome to think there are 7 million people in that city and none of them are using a car. People that violated this goal on this day were charged a 25 fine. People from other countries came to see how this day worked and they loved it. The mayor of Asuncion, Paraguay said \\\"These people are generating a revolutionary change, and this is crossing borders.\\\" You can just imagine all the benefits of everyone not using a car in a city for a whole day. Restaurants and parks would be visited and used more and everyone would be getting more exercise. All in all this idea was genius.\\n\\nAs you can see limiting car usage can help out the area big time that it is taking place. It is better breathing air, businesses like restaurants and parks would be used more and grow steadily, and the city would be taken care of better.\",\n          \"Limiting car usage could have many advantages on our planet. Many cities, such as Vauban in Germany, have given up on using cars to help the world around them. \\\"vaughn's streets are completely carfree,except the main thoroughfare, where the tram to downtown Freiburg runs, and a few streets on one edge of the community.\\\" There is a movement going on called, \\\"smart planning\\\" and Vauban is just one example of a growing trend in Europe of limiting auto use. The article says that passenger cars are responsible for twelve percent of greenhouse gas emissions in Europe. It seems that the people in Europe are realizing that so much car usage is harming their environment, and they are trying to set a trend for other countries like the United States to follow to limit using cars.\\n\\nHow much people use their cars is very important. Polluted air is a very widespread problem in many regions of the world. Paris had days of nearrecord pollution, and decided to enforce a partial driving ban to try to help clear the air of the city. The article says that almost 4,000 drivers were fined, and twentyseven had their cars impounded for their reaction to the fine. \\\"Congestion was down 60 percent in the capital of France, after five days of intensifying smog.\\\" The driving ban helped clear the smog, because it reduced car emissions. Paris has more smog than many other European capitals, which is why reducing how much citizens drive their cars is a good idea.\\n\\nSome cities have days that are completely car free. Bogota, Colombia is one of them. They have been having a Day Without Cars for three straight years. Cars are banned for the day and buses and taxis are the only exception. The city holds about 7 million people, and had a large turnout. \\\"It's a good opportunity to take away stress and lower air pollution,\\\" said businessman Carlos Arturo Plaza. The mayor of Asuncion, Paraguay even said that, \\\"These people are generating a revolutionary change, and this is crossing borders.\\\" The Day Without Cars has even helped stores and sports center come up throughout the city. Instead of shopping centers along a highway, those stores are now in the city and easy to get to without having to use a car.\\n\\nResearchers have been studying America's ways of car usage and driving. America is home to the first cars like the Model T, or \\\"Mustang Sally.\\\" Vehichles have always been a huge part of culture, but it seems now that that might not be the case anymore. \\\"As of April 2013, the number of miles driven per person was nearly 9 percent below the peak and equal to where the country was in January 1995.\\\" Researchers are actually hoping that the pattern continues because it will have beneficial implications for carbon emissions on the environment. Transportation is the second largest source, behind power plants, of emissions. Many changes have now happened in America, which are making using cars not as important. \\\"With all these changes, people who stopped car commuting as a result of the recession may find less reason to resume the habit..\\\" The article says. If we could slow down the usage of cars and emission, maybe we could help the planet become a better place.\\n\\nSince the percentage of car usage has gone down in America, so has the percentage of getting a license. There has been a large drop in 1639 year olds getting a license, Mr. Sivak's research has found. Older people are also likely to retain their licenses as they age. Mr. Sivak and another man both have children of about the same age, 19 and 21, and live in busy cities where a car could be useful. Neither one of them has their licenses, even though they are interested, but they don't really see the need for one when they can use public transportation or carpool with their friends. The article says that a study last year has also found that driving by young people decreased 23 percent between 2001 and 2009. Whether or not this changes as these young people grow older, these decreases in driving are proving that cars might just not be as important as they used to be.\\n\\nOur planet is just continuing to get worse from emissions from cars. Some countries are starting to realize this and are working hard to limit car usage and have citizens rely just on public transportation, walking, or riding a bike. Bill Ford proposed partnering with the telecommunications industry to create cities in which, \\\"pedestrian, bicycle, private cars, commercial, and public transportation traffic are woven into a connected network to save time, conserve resources, lower emissions, and improve safety.\\\" Citizens all over the world can work together to reduce car usage and better improve our planet.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"generated\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(src_train.shape)\n",
        "print(src_prompt.shape)\n",
        "print(src_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kd4AG32FCsgG",
        "outputId": "22b202b1-f7b8-44ae-e748-2c93360c4e3f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1378, 4)\n",
            "(2, 4)\n",
            "(3, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_save_path = \"bert-base-uncased\"\n",
        "model_save_path = \"fine_tuned_bert\"\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(tokenizer_save_path)\n",
        "\n",
        "pretrained_model = BertForSequenceClassification.from_pretrained(tokenizer_save_path, num_labels=2)\n",
        "\n",
        "embedding_model = BertEncoder(BertConfig())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAu5F34AEKsm",
        "outputId": "76574f50-3300-4dc2-c0c3-a0f5019bc405"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4. Set Hyperparameters\n",
        "train_batch_size = 16           # or 32 if your GPU allows it\n",
        "test_batch_size = 32            # inference usually uses a larger batch size\n",
        "lr = 2e-5                       # standard learning rate for BERT fine-tuning\n",
        "beta1 = 0.9                     # Adam optimizer's beta1 parameter (common default)\n",
        "nz = 100                        # latent vector size (used in GANs, not typical for BERT)\n",
        "num_epochs = 3                  # start with 3-5 epochs for BERT fine-tuning\n",
        "num_hidden_layers = 12          # BERT-base uses 12 hidden layers\n",
        "train_ratio = 0.8               # 80% of the data for training, 20% for validation"
      ],
      "metadata": {
        "id": "9RQUJA1iE-SR"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(src_train.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38hhCC6SFnvs",
        "outputId": "8b3d782a-23c0-4ed5-8069-77a3925dfc64"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'prompt_id', 'text', 'generated'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Prepare the Data for Training\n",
        "# Assuming src_train = pd.read_csv(TRAIN_PATH)\n",
        "# It contains columns: 'text' (input), 'label' (0=human, 1=AI-generated)\n",
        "\n",
        "all_num = len(src_train)\n",
        "train_num = int(all_num * train_ratio)\n",
        "test_num = all_num - train_num\n",
        "\n",
        "# Split your dataset\n",
        "train_set = src_train.iloc[:train_num]\n",
        "test_set = pd.concat([\n",
        "    src_train.iloc[train_num:]\n",
        "]).reset_index(drop=True)\n",
        "\n",
        "# Define Dataset class (if not already defined)\n",
        "class GANDAIGDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts[idx], self.labels[idx]\n",
        "\n",
        "# Create dataset objects\n",
        "train_dataset = GANDAIGDataset(\n",
        "    texts=list(train_set['text']),\n",
        "    labels=list(train_set['generated'])\n",
        ")\n",
        "\n",
        "test_dataset = GANDAIGDataset(\n",
        "    texts=list(test_set['text']),\n",
        "    labels=list(test_set['generated'])\n",
        ")\n",
        "\n",
        "# Create DataLoaders\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "NtJT4XYbFHby"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Generator definition\n",
        "from transformers import BertModel\n",
        "\n",
        "config = BertConfig(num_hidden_layers=num_hidden_layers)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(input_dim, 256 * 128)\n",
        "\n",
        "        self.conv_net = nn.Sequential(\n",
        "            nn.Conv1d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv1d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "        self.fc_embed = nn.Linear(256, 768)\n",
        "\n",
        "        # Use BertModel instead of BertEncoder here\n",
        "        self.bert_model = BertModel(config)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(-1, 256, 128)\n",
        "        x = self.conv_net(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        x = self.fc_embed(x)\n",
        "\n",
        "        # Now pass inputs_embeds to BertModel, not BertEncoder\n",
        "        outputs = self.bert_model(inputs_embeds=x)\n",
        "\n",
        "        return outputs.last_hidden_state\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AEBN__7DFy5v"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Define the Discriminator Model\n",
        "\n",
        "class SumBertPooler(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
        "        mean_embeddings = hidden_states.mean(dim=1)\n",
        "        return mean_embeddings\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.bert_encoder = BertEncoder(config)\n",
        "        self.bert_encoder.layer = nn.ModuleList([\n",
        "            layer for layer in pretrained_model.bert.encoder.layer[:6]\n",
        "        ])\n",
        "        self.pooler = SumBertPooler()\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(768, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, hidden_states, attention_mask=None):\n",
        "        out = self.bert_encoder(hidden_states, attention_mask=attention_mask)\n",
        "        pooled = self.pooler(out.last_hidden_state)  # or pass attention_mask if you update pooler\n",
        "        logits = self.classifier(pooled)\n",
        "        return torch.sigmoid(logits).view(-1)\n"
      ],
      "metadata": {
        "id": "rn-JSlkuGN1y"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Train the Model\n",
        "# ===== Functions =====\n",
        "\n",
        "embedding_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
        "\n",
        "def preparation_embedding(texts):\n",
        "    encodings = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "    input_ids = encodings['input_ids']\n",
        "    token_type_ids = encodings.get('token_type_ids')\n",
        "    attention_mask = encodings['attention_mask']\n",
        "\n",
        "    outputs = embedding_model(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
        "    return outputs.last_hidden_state\n",
        "\n",
        "\n",
        "def eval_auc(model):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            texts, labels = batch\n",
        "            embeded = preparation_embedding(texts)\n",
        "            outputs = model(embeded)\n",
        "            predictions.extend(outputs.cpu().numpy())\n",
        "            actuals.extend(labels.float().numpy())\n",
        "\n",
        "    auc = roc_auc_score(actuals, predictions)\n",
        "    print(\"AUC:\", auc)\n",
        "    return auc\n",
        "\n",
        "def get_model_info_dict(model, epoch, auc_score):\n",
        "    current_device = next(model.parameters()).device\n",
        "    model.to('cpu')\n",
        "    model_info = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'auc_score': auc_score,\n",
        "    }\n",
        "    model.to(current_device)\n",
        "    return model_info\n",
        "\n",
        "def GAN_step(optimizerG, optimizerD, netG, netD, real_data, label, epoch, i):\n",
        "    netD.zero_grad()\n",
        "    batch_size = real_data.size(0)\n",
        "\n",
        "    output = netD(real_data)\n",
        "    errD_real = criterion(output, label)\n",
        "    errD_real.backward()\n",
        "    D_x = output.mean().item()\n",
        "\n",
        "    noise = torch.randn(batch_size, nz, device=device)\n",
        "    fake_data = netG(noise).detach()\n",
        "    label_fake = torch.zeros(batch_size, device=device)\n",
        "\n",
        "    output = netD(fake_data)\n",
        "    errD_fake = criterion(output, label_fake)\n",
        "    errD_fake.backward()\n",
        "    D_G_z1 = output.mean().item()\n",
        "\n",
        "    errD = errD_real + errD_fake\n",
        "    optimizerD.step()\n",
        "\n",
        "    netG.zero_grad()\n",
        "    label_gen = torch.ones(batch_size, device=device)\n",
        "    output = netD(fake_data)\n",
        "    errG = criterion(output, label_gen)\n",
        "    errG.backward()\n",
        "    D_G_z2 = output.mean().item()\n",
        "    optimizerG.step()\n",
        "\n",
        "    if i % 50 == 0:\n",
        "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f' % (\n",
        "            epoch, num_epochs, i, len(train_loader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "\n",
        "    return optimizerG, optimizerD, netG, netD\n",
        "\n",
        "# ===== Initialize models, criterion, optimizers =====\n",
        "netG = Generator(input_dim=nz).to(device)\n",
        "netD = Discriminator().to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "\n",
        "# ===== Training =====\n",
        "model_infos = []\n",
        "for epoch in range(num_epochs):\n",
        "    netG.train()\n",
        "    netD.train()\n",
        "    for i, data in enumerate(train_loader):\n",
        "        texts, labels = data\n",
        "        labels = labels.float().to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            embeded = preparation_embedding(texts).to(device)\n",
        "\n",
        "        optimizerG, optimizerD, netG, netD = GAN_step(\n",
        "            optimizerG=optimizerG,\n",
        "            optimizerD=optimizerD,\n",
        "            netG=netG,\n",
        "            netD=netD,\n",
        "            real_data=embeded,\n",
        "            label=labels,\n",
        "            epoch=epoch, i=i)\n",
        "\n",
        "    auc_score = eval_auc(netD)\n",
        "    model_infos.append(get_model_info_dict(netD, epoch, auc_score))\n",
        "\n",
        "print('Train complete!')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvKTxqJhG0PL",
        "outputId": "b4c96d84-0e64-4462-d783-8b045a2f0678"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0/3][0/69] Loss_D: 1.2923 Loss_G: 0.9517 D(x): 0.4627 D(G(z)): 0.4885 / 0.3864\n",
            "[0/3][50/69] Loss_D: 0.0234 Loss_G: 4.5839 D(x): 0.0123 D(G(z)): 0.0110 / 0.0103\n",
            "AUC: 0.9927272727272727\n",
            "[1/3][0/69] Loss_D: 0.0140 Loss_G: 5.0309 D(x): 0.0069 D(G(z)): 0.0071 / 0.0067\n",
            "[1/3][50/69] Loss_D: 0.0066 Loss_G: 5.8194 D(x): 0.0035 D(G(z)): 0.0031 / 0.0030\n",
            "AUC: 0.9745454545454545\n",
            "[2/3][0/69] Loss_D: 0.0066 Loss_G: 6.0350 D(x): 0.0038 D(G(z)): 0.0028 / 0.0024\n",
            "[2/3][50/69] Loss_D: 0.0037 Loss_G: 6.4340 D(x): 0.0021 D(G(z)): 0.0017 / 0.0017\n",
            "AUC: 0.9672727272727273\n",
            "Train complete!\n"
          ]
        }
      ]
    }
  ]
}