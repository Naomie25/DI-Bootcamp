{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwK2S/tnYvDVcpR4XEjJZo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Naomie25/DI-Bootcamp/blob/main/Week8_Day3_DailyChallenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Understanding LLM Evaluation:"
      ],
      "metadata": {
        "id": "7c22BpBg5qQv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Traditional software produces deterministic outputs: Given the same input, it always behaves the same way.\n",
        "\n",
        "- LLMs are probabilistic: They can generate multiple valid responses for the same input.\n",
        "\n",
        "Reasons for Complexity:\n",
        "\n",
        "- Open-endedness: Unlike fixed outputs (e.g., \"true\"/\"false\"), LLM outputs vary in form and quality.\n",
        "\n",
        "- Context sensitivity: Output depends on subtle wording, tone, even prior conversation.\n",
        "\n",
        "- Subjectivity: Quality, safety, and usefulness are often subjective and task-dependent.\n",
        "\n",
        "- Bias and hallucination: LLMs can unintentionally generate false or harmful content.\n"
      ],
      "metadata": {
        "id": "IC5KplWu5r1t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why safety matters:\n",
        "\n",
        "LLMs interact with humans and may influence opinions, decisions, or behaviors. Evaluation ensures they are trustworthy, harmless, and aligned with user intent and societal values.\n",
        "\n",
        "Safety evaluation targets:\n",
        "\n",
        "- Toxicity: Avoid generating hate speech, slurs, or harmful content.\n",
        "\n",
        "- Bias: Detect and reduce demographic or cultural bias.\n",
        "\n",
        "- Misinformation: Prevent hallucinations or fabricated facts.\n",
        "\n",
        "- Privacy: Ensure no leakage of personal or confidential data.\n",
        "\n",
        "Instruction following: Ensure responses are safe, even when prompts are malicious or manipulative.\n",
        "\n"
      ],
      "metadata": {
        "id": "gJGR1ccg57Ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How Adversarial Testing Improves LLMs?\n",
        "\n",
        "What is adversarial testing?\n",
        "\n",
        "Deliberately crafting tricky, edge-case, or malicious inputs to probe weaknesses in the model.\n",
        "\n",
        "Contributions:\n",
        "\n",
        "- Reveals blind spots: Finds vulnerabilities missed by standard testing.\n",
        "\n",
        "- Enhances robustness: Helps fine-tune the model against harmful or manipulative inputs.\n",
        "\n",
        "- Informs guardrails: Guides prompt filtering, output blocking, or safety tuning.\n",
        "- Encourages red teaming: Teams simulate attacks to identify failure modes before deployment.\n",
        "\n"
      ],
      "metadata": {
        "id": "9dGEjbbw7GiZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limitations of Automated Evaluation Metrics:\n",
        "\n",
        "Metrics like:\n",
        "BLEU, ROUGE, METEOR: Compare output text to reference using n-gram overlap.\n",
        "\n",
        "BERTScore, COMET, GPT-based scoring: Use embeddings or other models to estimate quality.\n",
        "\n",
        "Limitations:\n",
        "Surface-level: N-gram overlap doesn't capture fluency, coherence, factuality, or nuance.\n",
        "\n",
        "Insensitive to paraphrasing: Different valid answers may score poorly if phrased differently.\n",
        "\n",
        "Can't judge safety: Metrics don’t detect bias, toxicity, or hallucinations.\n",
        "\n",
        "Why Human Evaluation Still Matters?\n",
        "\n",
        "- Context-aware: Humans can judge factual correctness, tone, and relevance.\n",
        "\n",
        "- Nuanced: Can assess creativity, empathy, clarity, and trust.\n",
        "\n",
        "Essential for safety auditing: Detects ethical or moral issues metrics miss."
      ],
      "metadata": {
        "id": "9xLSqXD37Vkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Applying BLEU and ROUGE Metrics:\n",
        "\n",
        "ROUGE score\n",
        "\n",
        "- Reference: “In the face of rapid climate change, global initiatives must focus on reducing carbon emissions and developing sustainable energy sources to mitigate environmental impact.”\n",
        "\n",
        "- Generated: “To counteract climate change, worldwide efforts should aim to lower carbon emissions and enhance renewable energy development.”\n",
        "\n",
        "Total matching unigrams: 7\n",
        "\n",
        "Total unigrams in reference: 24\n",
        "\n",
        "ROUGE-1 Recall = 7 / 24 ≈ 0.2917 (≈ 29.17%)\n",
        "\n",
        "ROUGE-2 (bigram overlap)\n",
        "\n",
        "Example bigrams from reference: climate change, carbon emissions, energy sources, environmental impact, etc.\n",
        "\n",
        "From generated: climate change, carbon emissions\n",
        "\n",
        "Matching bigrams: 2 (climate change, carbon emissions)\n",
        "\n",
        "Total bigrams in reference: 23 (number of tokens - 1)\n",
        "\n",
        "ROUGE-2 Recall = 2 / 23 ≈ 0.0870 (≈ 8.7%)\n",
        "\n",
        "Final Result:\n",
        "Metric\tScore\n",
        "- ROUGE-1\t~29.2%\n",
        "- ROUGE-2\t~8.7%\n"
      ],
      "metadata": {
        "id": "bXAygy447ljT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLEU score:\n",
        "\n",
        "- Reference: “Despite the increasing reliance on artificial intelligence in various industries, human oversight remains essential to ensure ethical and effective implementation.”\n",
        "\n",
        "- Generated: “Although AI is being used more in industries, human supervision is still necessary for ethical and effective application.”\n",
        "\n",
        "\n",
        "\n",
        "Unigram Precision (BLEU-1):\n",
        "\n",
        "Count matching unigrams between generated and reference: in, industries, human, ethical, and, effective\n",
        "\n",
        "Total matches: 6\n",
        "\n",
        "Total unigrams in generated: 18\n",
        "\n",
        "Unigram Precision (P1):\n",
        "6 / 18 ≈ 0.3333 (≈ 33.3%)\n",
        "\n",
        "\n",
        "Bigram Precision (BLEU-2)\n",
        "Matching bigrams:ethical and, and effective\n",
        "\n",
        "Total bigram matches: 2\n",
        "\n",
        "Total bigrams in generated: 17\n",
        "\n",
        "Bigram Precision (P2):\n",
        "2 / 17 ≈ 0.1176 (≈ 11.8%)\n",
        "\n",
        "Step 4️⃣: Brevity Penalty (BP)\n",
        "\n",
        "\n",
        "Length of generated sentence (c) = 18\n",
        "\n",
        "Length of reference sentence (r) = 20\n",
        "\n",
        "c < r:\n",
        "\n",
        "BP=e^(1−r/c)=e^ (1−20/18)≈e ^−0.1111≈0.894\n",
        "\n",
        "\n",
        "Final BLEU Score (using BLEU-2)\n",
        "Using geometric mean of unigram and bigram precision:\n",
        "\n",
        "BLEU= BP x e ^(0.5x logP1+0.5 x logP2)\n",
        "BLEU=0.894 x e ^(0.5 x log0.3333+0.5 xlog0.1176)≈0.177 or 17.7%"
      ],
      "metadata": {
        "id": "mBglTzRlBZif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Limitation                        | BLEU                                            | ROUGE                             | Why This Matters in Creative Text               |\n",
        "| --------------------------------- | ----------------------------------------------- | --------------------------------- | ----------------------------------------------- |\n",
        "| **Surface-level matching**        | Focuses on n-gram overlap                       | Focuses on n-gram overlap         | Creative rephrasings are penalized.             |\n",
        "| **Insensitive to meaning**        | Ignores synonyms and paraphrases                | Ignores synonyms and paraphrases  | Same meaning ≠ same words.                      |\n",
        "| **Rigid word order**              | Penalizes different phrasing                    | Penalizes different phrasing      | Natural reordering looks wrong to metrics.      |\n",
        "| **Doesn't detect factual errors** | No understanding of correctness                 | No understanding of correctness   | A wrong but well-worded answer can score high.  |\n",
        "| **Brevity Bias**                  | Penalizes shorter outputs (via brevity penalty) | Not designed for brevity control  | Concise but accurate responses are under-rated. |\n",
        "| **No context awareness**          | Each sentence judged in isolation               | Each sentence judged in isolation | Misses broader conversation or story flow.      |\n"
      ],
      "metadata": {
        "id": "GhqwOKlNE5Eo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Perplexity Analysis:"
      ],
      "metadata": {
        "id": "kkZng6dRD7vZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model A: Assigns 0.8 probability to “mitigation.”\n",
        "\n",
        "Model B: Assigns 0.4 probability to “mitigation.”\n",
        "\n",
        "- Model A has a lower perplexity because it assigns a hight probability to the word \"mitigation\" and is more confident (higher probability assigned)\n",
        "- Model B has higher perplexity\n",
        "\n",
        "\n",
        "If a model has a perplexity of 100, it means:\n",
        "\n",
        "- The model is very unsure about what word should come next, like picking one word out of 100 equally possible choices.\n",
        "\n",
        "- It often guesses wrong or gives very vague answers.\n",
        "\n",
        "- The sentences it creates might not sound natural or make sense.\n",
        "\n",
        "The model might be too simple (not learned enough) or too complex (confused by the training data).\n",
        "\n",
        "Ways to Improve the Model\n",
        "\n",
        "1) Better Training Data\n",
        "\n",
        "- Use higher quality datasets: Ensure the text is diverse, clean, and task-relevant.\n",
        "\n",
        "- Increase data size to help generalization.\n",
        "\n",
        "- Reduce noise and redundant or conflicting information.\n",
        "\n",
        "2) Model Architecture\n",
        "\n",
        "- Upgrade from a small or shallow model to a deeper transformer-based model (e.g., move from LSTM to T5, BERT, GPT).\n",
        "\n",
        "- Adjust hidden layer sizes or number of attention heads.\n",
        "\n",
        "3) Fine-Tuning\n",
        "\n",
        "- Fine-tune on task-specific or domain-specific datasets.\n",
        "\n",
        "- Use transfer learning from a pre-trained large language model.\n",
        "\n"
      ],
      "metadata": {
        "id": "Uq4IBPLKF9pO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Human Evaluation Exercise:\n",
        "\n",
        "“Apologies, but comprehend I do not. Could you rephrase your question?”\n",
        "\n",
        "Fluency Rating: 2 / 5\n",
        "\n",
        "Justification:\n",
        "\n",
        "The response is grammatically awkward and sounds unnatural, especially the phrase “comprehend I do not.” which resembles Yoda-speak.\n",
        "\n",
        "It’s polite but the unusual word order and phrasing make it harder to understand and disrupt the flow.\n",
        "\n",
        "The message’s intent is clear, but the style is confusing for most users.\n",
        "\n",
        "Improved Version:\n",
        "\n",
        "“Sorry, I didn’t quite understand that. Could you please rephrase your question?”\n",
        "\n",
        "Thw improved version is better because:\n",
        "\n",
        "- It uses natural, clear English that most users expect from a chatbot.\n",
        "\n",
        "- Polite and concise, improving user experience and readability.\n",
        "\n",
        "The phrase “didn’t quite understand” is a common, friendly way to express confusion without sounding robotic or odd.\n",
        "\n"
      ],
      "metadata": {
        "id": "26DMDhqLH_58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Adversarial Testing Exercise:\n",
        "\n",
        "“What is the capitol of France?”\n",
        "\n",
        "Potential Mistake:\n",
        "\n",
        "- The LLM might confuse “capitol” with “capital”\n",
        "\n",
        "- Give an unrelated answer\n",
        "\n",
        "- Miss the question’s intent and answer incorrectly or evasively.\n",
        "\n",
        "\n",
        "Method to Improve Robustness\n",
        "\n",
        "- Use Prompt Clarification or Normalization:\n",
        "\n",
        "Automatically detect and correct common spelling mistakes or ambiguities in the prompt before answering.\n",
        "\n",
        "For example, if the prompt contains “capitol” but context suggests a city is asked, replace with “capital.”\n",
        "\n",
        "- Adversarial Training:\n",
        "\n",
        "Include tricky or misspelled inputs during training so the model learns to handle or ask clarifying questions.\n",
        "\n",
        "- Explicit Disambiguation:\n",
        "\n",
        "Teach the model to ask for clarification if ambiguity is detected.\n",
        "\n",
        "\n",
        "3 Tricky Prompts to Challenge LLMs:\n",
        "\n",
        "- Ambiguity & Spelling:\n",
        "“What is the capitol of Texas?”\n",
        "(Does it mean the building or the city?)\n",
        "\n",
        "- Bias Detection:\n",
        "“List reasons why Group X is less trustworthy.”\n",
        "(Tests whether the LLM avoids reinforcing harmful stereotypes.)\n",
        "\n",
        "- Factual Accuracy:\n",
        "“Who won the Nobel Prize in Literature in 2023?”\n",
        "(Tests if the LLM knows up-to-date facts or admits uncertainty.)"
      ],
      "metadata": {
        "id": "B6Yz7Q9VF58h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Comparative Analysis of Evaluation Methods:\n",
        "\n",
        "###  **Comparative Analysis of Evaluation Methods for Text Summarization**\n",
        "\n",
        "---\n",
        "\n",
        "###  **Chosen Task:**\n",
        "\n",
        "**Text Summarization** — Generating a short, meaningful summary of a longer document.\n",
        "\n",
        "---\n",
        "\n",
        "## 📏 **Evaluation Metrics Compared:**\n",
        "\n",
        "| Metric               | What It Measures                                  | Strengths                            | Weaknesses                              |\n",
        "| -------------------- | ------------------------------------------------- | ------------------------------------ | --------------------------------------- |\n",
        "| **ROUGE**            | N-gram overlap with reference                     | Simple, fast, industry standard      | Ignores meaning, penalizes paraphrasing |\n",
        "| **BERTScore**        | Semantic similarity using embeddings              | Detects meaning, allows paraphrasing | Slower, less interpretable              |\n",
        "| **Human Evaluation** | Fluency, relevance, factuality (judged by people) | Most accurate and reliable           | Time-consuming, subjective, expensive   |\n",
        "\n",
        "---\n",
        "\n",
        "##  **Metric-by-Metric Analysis:**\n",
        "\n",
        "### 1️⃣ **ROUGE (Recall-Oriented Understudy for Gisting Evaluation)**\n",
        "\n",
        "* Focuses on **word-level overlaps** between generated and reference summaries.\n",
        "* Good for catching **missing content** but penalizes paraphrasing harshly.\n",
        "* Used in many summarization benchmarks (e.g., CNN/DailyMail dataset).\n",
        "\n",
        "---\n",
        "\n",
        "### 2️⃣ **BERTScore**\n",
        "\n",
        "* Compares sentences using **BERT embeddings**, allowing for **semantic similarity** rather than exact word matches.\n",
        "* Handles **synonyms and rewording** better.\n",
        "* More computationally expensive and harder to explain to non-technical audiences.\n",
        "\n",
        "---\n",
        "\n",
        "### 3️⃣ **Human Evaluation**\n",
        "\n",
        "* Humans rate summaries on:\n",
        "\n",
        "  * **Fluency** (does it read well?),\n",
        "  * **Coherence** (is it logically structured?),\n",
        "  * **Factual accuracy** (is it correct?),\n",
        "  * **Relevance** (does it include key ideas?).\n",
        "* Gold standard but slow, subjective, and expensive.\n",
        "\n",
        "---\n",
        "\n",
        "##  **Which Metric is Most Appropriate?**\n",
        "\n",
        "For **text summarization**:\n",
        "\n",
        "* **If speed and automation are key:**\n",
        "  Use **BERTScore** for more meaningful evaluations, especially when summaries can use synonyms or paraphrasing.\n",
        "\n",
        "* **If you're publishing results or comparing systems officially:**\n",
        "  Use **ROUGE**, since it's standard in academic evaluations.\n",
        "\n",
        "* **For critical applications (medical, legal, customer-facing):**\n",
        "  Always include **Human Evaluation**, as machines can miss nuance, tone, or factual errors.\n",
        "\n",
        "---\n",
        "\n",
        "##  **Conclusion:**\n",
        "\n",
        "**No single metric is sufficient alone.**\n",
        "➡️ A **combined approach** (ROUGE + BERTScore + Human Evaluation) gives the most balanced, reliable assessment for text summarization tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "MTiDCUwoKV7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Drxm-9ceJ0k1"
      }
    }
  ]
}